{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "happy-triple",
   "metadata": {},
   "source": [
    "# 1. Simplitied Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "seven-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "\n",
    "    def _entropy(self, y): \n",
    "        counts = np.bincount(y)  # Count the occurrences of each class\n",
    "        probs = counts / len(y)  # Calculate class probabilities\n",
    "        return -np.sum(probs * np.log2(probs + 1e-6))  # Compute entropy\n",
    "\n",
    "    def _information_gain(self, y, splits): \n",
    "        total = len(y)\n",
    "        entropy_y = self._entropy(y)  # Entropy of y\n",
    "        entropy_splits = 0\n",
    "\n",
    "        for split in splits:\n",
    "            weight = len(split) / total  # Weight of the split\n",
    "            entropy_splits += weight * self._entropy(split)  # Entropy of each splits\n",
    "\n",
    "        return entropy_y - entropy_splits\n",
    "    \n",
    "    def _split_information(self, splits):\n",
    "        total = len(np.concatenate(splits))\n",
    "        split_info = 0\n",
    "\n",
    "        for split in splits:\n",
    "            if len(split) > 0:\n",
    "                p_i = len(split) / total\n",
    "                split_info -= p_i * np.log2(p_i)\n",
    "\n",
    "        return split_info\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gain_ratio = 0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            unique_values = np.unique(X[:, feature])  # thredshold is on training points\n",
    "            for threshold in unique_values: \n",
    "                left_mask = X[:, feature] >= threshold\n",
    "                right_mask = ~left_mask\n",
    "\n",
    "                if len(y[left_mask]) > 0 and len(y[right_mask]) > 0:\n",
    "                    splits = [y[left_mask], y[right_mask]]\n",
    "                    gain = self._information_gain(y, splits)  # Information gain for current thredshold\n",
    "                    split_info = self._split_information(splits)\n",
    "                    gain_ratio = gain / (split_info + 1e-6)\n",
    "\n",
    "                    if gain_ratio > best_gain_ratio:\n",
    "                        best_gain_ratio = gain_ratio\n",
    "                        best_feature = feature\n",
    "                        best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _build_tree(self, X, y):\n",
    "        \n",
    "        # the entropy of any candidates split is zero\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return int(y[0])  # Return a leaf node with the class if all labels are the same\n",
    "\n",
    "        # the node is empty\n",
    "        if len(X) == 0:\n",
    "            return int(1)  # Predict y = 1 when no majority class\n",
    "\n",
    "        feature, threshold = self._best_split(X, y)\n",
    "\n",
    "        # all splits have zero gain ratio\n",
    "        if feature is None:\n",
    "            return int(1)  # Predict y = 1 when no majority class\n",
    "\n",
    "        left_mask = X[:, feature] >= threshold\n",
    "        right_mask = ~left_mask\n",
    "\n",
    "        left_subtree = self._build_tree(X[left_mask], y[left_mask])  # Recursively build left subtree\n",
    "        right_subtree = self._build_tree(X[right_mask], y[right_mask])  # Recursively build right subtree\n",
    "\n",
    "        return (int(feature), threshold, left_subtree, right_subtree)  # Return a decision node\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            node = self.tree\n",
    "            while isinstance(node, tuple):\n",
    "                feature, threshold, left, right = node\n",
    "                if x[feature] >= threshold:\n",
    "                    node = left  # Traverse left subtree\n",
    "                else:\n",
    "                    node = right  # Traverse right subtree\n",
    "            predictions.append(node)\n",
    "\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def visualize_tree(self):\n",
    "        self._visualize_node(self.tree, depth=0)\n",
    "\n",
    "    def _visualize_node(self, node, depth):\n",
    "        if isinstance(node, int):\n",
    "            print(f\"{'  ' * depth}Class {node}\")\n",
    "        else:\n",
    "            feature, threshold, left, right = node\n",
    "            print(f\"{'  ' * depth}Feature {feature} >= {threshold}\")\n",
    "            self._visualize_node(left, depth + 1)\n",
    "            self._visualize_node(right, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-recall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "latin-palmer",
   "metadata": {},
   "source": [
    "# 2. Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-planet",
   "metadata": {},
   "source": [
    "## 2-2. Our algorithm is greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "automotive-witness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1.2, 2.3], [2.1, 1.9], [3.5, 4.0]])\n",
    "y = np.array([0, 1, 0])\n",
    "\n",
    "tree = DecisionTree()\n",
    "tree.fit(X, y)\n",
    "\n",
    "test_data = np.array([[2.8, 3.2], [1.0, 2.0]])\n",
    "predictions = tree.predict(test_data)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-apparatus",
   "metadata": {},
   "source": [
    "## 2-3. Information gain ration exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "precise-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "druns = pd.read_csv('./Homework 2 data/Druns.txt', sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-saying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "marked-bhutan",
   "metadata": {},
   "source": [
    "## 2-4. The king of interpretabilit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "blind-baptist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0 >= 10\n",
      "  Class 1\n",
      "  Feature 1 >= 3\n",
      "    Class 1\n",
      "    Class 0\n"
     ]
    }
   ],
   "source": [
    "d3leaves = pd.read_csv('./Homework 2 data/D3leaves.txt', sep=\" \", header=None)\n",
    "\n",
    "tree_d3leaves = DecisionTree()\n",
    "tree_d3leaves.fit(np.array(d3leaves[[0, 1]]), np.array(d3leaves[2]))\n",
    "\n",
    "tree_d3leaves.visualize_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-paraguay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
